{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a2b0c05d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|im_start|>system\n",
      "Test system message<|im_end|>\n",
      "<|im_start|>user\n",
      "<image>\n",
      "Hello!<|im_end|>\n",
      "<|im_start|>assistant\n",
      "Hi there!<|im_end|>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from jinja2 import Template\n",
    "\n",
    "CHAT_TEMPLATE = \"\"\"\n",
    "{%- set nl = '\\\\n' -%}\n",
    "{%- set im_start = '<|im_start|>' -%}\n",
    "{%- set im_end = '<|im_end|>' -%}\n",
    "{{- im_start -}}system{{- nl -}}{{- system_message -}}{{- im_end -}}{{- nl -}}\n",
    "{%- for message in messages -%}\n",
    "    {%- if message.from == 'human' -%}\n",
    "        {{- im_start -}}user{{- nl -}}\n",
    "        {%- if message.value is not none -%}\n",
    "            {%- set parts = message.value.split('<image>') -%}\n",
    "            {%- for part in parts -%}\n",
    "                {{- part -}}\n",
    "                {%- if not loop.last -%}<image>{{- nl -}}{%- endif -%}\n",
    "            {%- endfor -%}\n",
    "        {%- endif -%}\n",
    "        {{- im_end -}}{{- nl -}}\n",
    "    {%- elif message.from == 'gpt' -%}\n",
    "        {{- im_start -}}assistant{{- nl -}}\n",
    "        {{- message.value if message.value is not none else '' -}}\n",
    "        {{- im_end -}}{{- nl -}}\n",
    "    {%- endif -%}\n",
    "{%- endfor -%}\n",
    "\"\"\"\n",
    "\n",
    "conversation = [\n",
    "        {\"from\": \"human\", \"value\": \"<image>Hello!\"},\n",
    "        {\"from\": \"gpt\", \"value\": \"Hi there!\"}\n",
    "]\n",
    "system_message = \"Test system message\"\n",
    "template = Template(CHAT_TEMPLATE)\n",
    "rendered = template.render(\n",
    "    system_message=system_message,\n",
    "    messages=conversation\n",
    ")\n",
    "print(rendered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0b7da7c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "import torch, re\n",
    "from llava.constants import IGNORE_INDEX, DEFAULT_IMAGE_TOKEN, IMAGE_TOKEN_INDEX, DEFAULT_IMAGE_PATCH_TOKEN, DEFAULT_IM_START_TOKEN, DEFAULT_IM_END_TOKEN\n",
    "\n",
    "def preprocess_qwen(sources, tokenizer, has_image: bool = False, max_len=2048, system_message: str = \"You are a helpful assistant.\"):\n",
    "    roles = {\"human\": \"<|im_start|>user\", \"gpt\": \"<|im_start|>assistant\"}\n",
    "    im_start, im_end = tokenizer.additional_special_tokens_ids\n",
    "    nl_tokens = tokenizer(\"\\n\").input_ids\n",
    "    _system = tokenizer(\"system\").input_ids + nl_tokens\n",
    "    input_ids = []\n",
    "    source = sources\n",
    "    if roles[source[0][\"from\"]] != roles[\"human\"]: source = source[1:]\n",
    "    input_id, target = [], []\n",
    "    system = [im_start] + _system + tokenizer(system_message).input_ids + [im_end] + nl_tokens\n",
    "    input_id += system\n",
    "    target += [im_start] + [IGNORE_INDEX] * (len(system) - 3) + [im_end] + nl_tokens\n",
    "    assert len(input_id) == len(target)\n",
    "    for j, sentence in enumerate(source):\n",
    "        role = roles[sentence[\"from\"]]\n",
    "        if has_image and sentence[\"value\"] is not None and \"<image>\" in sentence[\"value\"]:\n",
    "            num_image = len(re.findall(DEFAULT_IMAGE_TOKEN, sentence[\"value\"]))\n",
    "            texts = sentence[\"value\"].split('<image>')\n",
    "            _input_id = tokenizer(role).input_ids + nl_tokens \n",
    "            for i,text in enumerate(texts):\n",
    "                _input_id += tokenizer(text).input_ids \n",
    "                if i<len(texts)-1: _input_id += [IMAGE_TOKEN_INDEX] + nl_tokens\n",
    "            _input_id += [im_end] + nl_tokens\n",
    "            assert sum([i==IMAGE_TOKEN_INDEX for i in _input_id])==num_image\n",
    "        else:\n",
    "            if sentence[\"value\"] is None: _input_id = tokenizer(role).input_ids + nl_tokens\n",
    "            else: _input_id = tokenizer(role).input_ids + nl_tokens + tokenizer(sentence[\"value\"]).input_ids + [im_end] + nl_tokens\n",
    "        input_id += _input_id\n",
    "    input_ids.append(input_id)\n",
    "    return torch.tensor(input_ids, dtype=torch.long)\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained('neulab/Pangea-7B')\n",
    "tokenizer.add_tokens([DEFAULT_IMAGE_PATCH_TOKEN], special_tokens=True)\n",
    "tokenizer.add_tokens([DEFAULT_IM_START_TOKEN, DEFAULT_IM_END_TOKEN], special_tokens=True)\n",
    "tokenizer.add_tokens([DEFAULT_IMAGE_TOKEN], special_tokens=True)\n",
    "input_ids = preprocess_qwen(conversation, tokenizer, has_image=True, system_message=system_message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f17f02e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[151644,   8948,    198,   2271,   1849,   1943, 151645,    198, 151644,\n",
       "            872,    198,   -200,    198,   9707,      0, 151645,    198, 151644,\n",
       "          77091,    198,  13048,   1052,      0, 151645,    198]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dbddb878",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "151650"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenizer.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a8d81453",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_input_ids = tokenizer(rendered)[\"input_ids\"]\n",
    "image_token_id = tokenizer.convert_tokens_to_ids(DEFAULT_IMAGE_TOKEN)\n",
    "new_input_ids[new_input_ids.index(image_token_id)] = IMAGE_TOKEN_INDEX\n",
    "new_input_ids == input_ids[0].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fbd66d24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "151649"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenizer.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "004a9ab4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|im_start|>system\n",
      "Test system message<|im_end|>\n",
      "<|im_start|>user\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.decode(input_ids[0][:11]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "97427f63",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the dataset since CNCL-Penn-State/cpo_en_multitask_text_fa_msd5_mm10_ms20_div_nov_sur_qua couldn't be found on the Hugging Face Hub\n",
      "Found the latest cached dataset configuration 'default' at /home/ismayilz/.cache/huggingface/datasets/CNCL-Penn-State___cpo_en_multitask_text_fa_msd5_mm10_ms20_div_nov_sur_qua/default/0.0.0/b25b8f9b353c159240dc7fc4f25c3221eab75ed0 (last modified on Thu May 29 10:27:52 2025).\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "input_dataset = load_dataset(\"CNCL-Penn-State/cpo_en_multitask_text_fa_msd5_mm10_ms20_div_nov_sur_qua\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "58456c2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['dataset', 'task', 'score_label', 'score_chosen', 'score_rejected', 'chosen', 'rejected', 'novelty_chosen', 'surprise_chosen', 'diversity_chosen', 'quality_chosen'],\n",
       "        num_rows: 42058\n",
       "    })\n",
       "    val: Dataset({\n",
       "        features: ['dataset', 'task', 'score_label', 'score_chosen', 'score_rejected', 'chosen', 'rejected', 'novelty_chosen', 'surprise_chosen', 'diversity_chosen', 'quality_chosen'],\n",
       "        num_rows: 4880\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['dataset', 'task', 'score_label', 'score_chosen', 'score_rejected', 'chosen', 'rejected', 'novelty_chosen', 'surprise_chosen', 'diversity_chosen', 'quality_chosen'],\n",
       "        num_rows: 4533\n",
       "    })\n",
       "    heldout_item: Dataset({\n",
       "        features: ['dataset', 'task', 'score_label', 'score_chosen', 'score_rejected', 'chosen', 'rejected', 'novelty_chosen', 'surprise_chosen', 'diversity_chosen', 'quality_chosen'],\n",
       "        num_rows: 3521\n",
       "    })\n",
       "    heldout_task: Dataset({\n",
       "        features: ['dataset', 'task', 'score_label', 'score_chosen', 'score_rejected', 'chosen', 'rejected', 'novelty_chosen', 'surprise_chosen', 'diversity_chosen', 'quality_chosen'],\n",
       "        num_rows: 52\n",
       "    })\n",
       "    val_sample1024: Dataset({\n",
       "        features: ['dataset', 'task', 'score_label', 'score_chosen', 'score_rejected', 'chosen', 'rejected', 'novelty_chosen', 'surprise_chosen', 'diversity_chosen', 'quality_chosen'],\n",
       "        num_rows: 744\n",
       "    })\n",
       "    val_sample4096: Dataset({\n",
       "        features: ['dataset', 'task', 'score_label', 'score_chosen', 'score_rejected', 'chosen', 'rejected', 'novelty_chosen', 'surprise_chosen', 'diversity_chosen', 'quality_chosen'],\n",
       "        num_rows: 2356\n",
       "    })\n",
       "    test_sample1024: Dataset({\n",
       "        features: ['dataset', 'task', 'score_label', 'score_chosen', 'score_rejected', 'chosen', 'rejected', 'novelty_chosen', 'surprise_chosen', 'diversity_chosen', 'quality_chosen'],\n",
       "        num_rows: 720\n",
       "    })\n",
       "    test_sample4096: Dataset({\n",
       "        features: ['dataset', 'task', 'score_label', 'score_chosen', 'score_rejected', 'chosen', 'rejected', 'novelty_chosen', 'surprise_chosen', 'diversity_chosen', 'quality_chosen'],\n",
       "        num_rows: 2373\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f222a301",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "from tqdm import tqdm \n",
    "\n",
    "def extend_dataset(dataset):\n",
    "    extended_data = []\n",
    "    for sample in tqdm(dataset):\n",
    "        extended_data.append({\n",
    "            **sample,\n",
    "            \"chosen\": [{\"role\": \"user\", \"content\": f\"<image>{sample['chosen'][0]['content']}\"}, sample[\"chosen\"][1]],\n",
    "            \"rejected\": [{\"role\": \"user\", \"content\": f\"<image>{sample['rejected'][0]['content']}\"}, sample[\"rejected\"][1]],\n",
    "            \"image\": \"data/images/general/allava-4v/89708.jpeg\"\n",
    "        })\n",
    "    return Dataset.from_generator(lambda: extended_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1a9f6854",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 42058/42058 [00:03<00:00, 10793.10it/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64e5d74143d046e3b4ed14fc378134f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4880/4880 [00:00<00:00, 11657.71it/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c902c91d13d141a79b114495ae23c87d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4533/4533 [00:00<00:00, 11638.98it/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b7d3aa38b6c4888b0f87774c7170d42",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3521/3521 [00:00<00:00, 11798.15it/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34f6a13bb5744cc283af0d619b20b5ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 52/52 [00:00<00:00, 10938.00it/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "350d7a7f359248f68c375dd16b56a9b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 744/744 [00:00<00:00, 11811.10it/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f2510c2f1524db7b698f7f80ac8c0d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2356/2356 [00:00<00:00, 11381.77it/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e90166ce8704372a233c29057e941f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 720/720 [00:00<00:00, 11322.31it/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b748b659ca6b420e9599556ca95c4c38",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2373/2373 [00:00<00:00, 11696.63it/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d084603419d48bb8ba50f5e22762d52",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for split in input_dataset.keys():\n",
    "    input_dataset[split] = extend_dataset(input_dataset[split])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "82cd8e72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['dataset', 'task', 'score_label', 'score_chosen', 'score_rejected', 'chosen', 'rejected', 'novelty_chosen', 'surprise_chosen', 'diversity_chosen', 'quality_chosen', 'image'],\n",
       "        num_rows: 42058\n",
       "    })\n",
       "    val: Dataset({\n",
       "        features: ['dataset', 'task', 'score_label', 'score_chosen', 'score_rejected', 'chosen', 'rejected', 'novelty_chosen', 'surprise_chosen', 'diversity_chosen', 'quality_chosen', 'image'],\n",
       "        num_rows: 4880\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['dataset', 'task', 'score_label', 'score_chosen', 'score_rejected', 'chosen', 'rejected', 'novelty_chosen', 'surprise_chosen', 'diversity_chosen', 'quality_chosen', 'image'],\n",
       "        num_rows: 4533\n",
       "    })\n",
       "    heldout_item: Dataset({\n",
       "        features: ['dataset', 'task', 'score_label', 'score_chosen', 'score_rejected', 'chosen', 'rejected', 'novelty_chosen', 'surprise_chosen', 'diversity_chosen', 'quality_chosen', 'image'],\n",
       "        num_rows: 3521\n",
       "    })\n",
       "    heldout_task: Dataset({\n",
       "        features: ['dataset', 'task', 'score_label', 'score_chosen', 'score_rejected', 'chosen', 'rejected', 'novelty_chosen', 'surprise_chosen', 'diversity_chosen', 'quality_chosen', 'image'],\n",
       "        num_rows: 52\n",
       "    })\n",
       "    val_sample1024: Dataset({\n",
       "        features: ['dataset', 'task', 'score_label', 'score_chosen', 'score_rejected', 'chosen', 'rejected', 'novelty_chosen', 'surprise_chosen', 'diversity_chosen', 'quality_chosen', 'image'],\n",
       "        num_rows: 744\n",
       "    })\n",
       "    val_sample4096: Dataset({\n",
       "        features: ['dataset', 'task', 'score_label', 'score_chosen', 'score_rejected', 'chosen', 'rejected', 'novelty_chosen', 'surprise_chosen', 'diversity_chosen', 'quality_chosen', 'image'],\n",
       "        num_rows: 2356\n",
       "    })\n",
       "    test_sample1024: Dataset({\n",
       "        features: ['dataset', 'task', 'score_label', 'score_chosen', 'score_rejected', 'chosen', 'rejected', 'novelty_chosen', 'surprise_chosen', 'diversity_chosen', 'quality_chosen', 'image'],\n",
       "        num_rows: 720\n",
       "    })\n",
       "    test_sample4096: Dataset({\n",
       "        features: ['dataset', 'task', 'score_label', 'score_chosen', 'score_rejected', 'chosen', 'rejected', 'novelty_chosen', 'surprise_chosen', 'diversity_chosen', 'quality_chosen', 'image'],\n",
       "        num_rows: 2373\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e3bd47e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dataset': '1.Becky.csv',\n",
       " 'task': 'Real-Life Creative Problem Solving',\n",
       " 'score_label': 'originality',\n",
       " 'score_chosen': 34.0,\n",
       " 'score_rejected': 24.0,\n",
       " 'chosen': [{'content': \"<image>Come up with an original and creative solution for the following real-world problem:\\nBecky is a college student who works part-time at Mark's Pizzeria. Mark, the owner of the restaurant, has treated Becky very well. He gave her a job that she needs to help pay her rent when no other business would employ her because she was arrested for shoplifting three years ago. Mark also lets Becky work around her school schedule, and has asked if she wants to be a shift manager in the summers. Becky's roommate Jim also works at the pizzeria, but Jim has been causing a lot of problems at work. He always avoids doing his job, treats customers rudely, and makes a lot of mistakes with orders. Jim recently began stealing food from the pizzeria. Two days ago the pizzeria was short- staffed, so Jim and Becky were the only employees left at closing time. Jim made 10 extra pizzas and took them home to a party he was hosting without paying for them. Becky feels like she needs to do something about Jim's behavior. However, Becky is hesitant to tell Mark about Jim because Jim is a good friend to Becky. Becky also needs Jim to have a job so he can pay his portion of their rent. Becky does not know what to do..\",\n",
       "   'role': 'user'},\n",
       "  {'content': 'She could leave an anonymous note for the manager saying one of the employees was stealing.',\n",
       "   'role': 'assistant'}],\n",
       " 'rejected': [{'content': \"<image>Come up with an original and creative solution for the following real-world problem:\\nBecky is a college student who works part-time at Mark's Pizzeria. Mark, the owner of the restaurant, has treated Becky very well. He gave her a job that she needs to help pay her rent when no other business would employ her because she was arrested for shoplifting three years ago. Mark also lets Becky work around her school schedule, and has asked if she wants to be a shift manager in the summers. Becky's roommate Jim also works at the pizzeria, but Jim has been causing a lot of problems at work. He always avoids doing his job, treats customers rudely, and makes a lot of mistakes with orders. Jim recently began stealing food from the pizzeria. Two days ago the pizzeria was short- staffed, so Jim and Becky were the only employees left at closing time. Jim made 10 extra pizzas and took them home to a party he was hosting without paying for them. Becky feels like she needs to do something about Jim's behavior. However, Becky is hesitant to tell Mark about Jim because Jim is a good friend to Becky. Becky also needs Jim to have a job so he can pay his portion of their rent. Becky does not know what to do..\",\n",
       "   'role': 'user'},\n",
       "  {'content': 'Becky should start by talking to Jim about this problem, and tell him that if he does not stop doing what he is doing she will have to report him.  He may be a good friend to Becky but if its found out that she knew about his behavior and did nothing it culd be her job that she loses.',\n",
       "   'role': 'assistant'}],\n",
       " 'novelty_chosen': 0.5916894248421661,\n",
       " 'surprise_chosen': 0.4943820224719101,\n",
       " 'diversity_chosen': 0.6028493145130767,\n",
       " 'quality_chosen': 0.4826762246117085,\n",
       " 'image': 'data/images/general/allava-4v/89708.jpeg'}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_dataset[\"train\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "457b3b46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff8eded83ed64c99918f03ec57658278",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0e47d3cc3e141988682d86a0a8c89a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/43 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07c46f34d2314eb8a90138d80707f178",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b06a4dcb0a784475a3e8f0efd98fee39",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/5 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8139ab270b344feb92eaa9f37f956328",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f864a588e444fbe915e13fab4df6c3f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/5 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63664c44699b4240a0e595d4b29750c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e0f9753f3ca4997a193b8e5d8987955",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/4 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d898f80de4314cd0bde0a9af69f56d91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1ac7ebe6ca24a0983b1a1013fbbd148",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b15c033a6f1849279492954db82598d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76878a3163724919ae463fe3bf84ae68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b07ae3dd28ab4105958759cc66311697",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae51043881e7483f98d0ba290efe1b2b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/3 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12ae3e85823e4003ae353431fdb0e4c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "535043a2c6c4401a9d74ebb5c17c5661",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d84434a496644a21bc730be70d0459d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de04edb5b12f4b8a8cddaf72045153f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/3 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/datasets/CNCL-Penn-State/cpo_en_multitask_text_fa_msd5_mm10_ms20_div_nov_sur_qua_test/commit/efcfa9cfc8b93b41dba4cf7f7f07fc56ac9fe93f', commit_message='Upload dataset', commit_description='', oid='efcfa9cfc8b93b41dba4cf7f7f07fc56ac9fe93f', pr_url=None, repo_url=RepoUrl('https://huggingface.co/datasets/CNCL-Penn-State/cpo_en_multitask_text_fa_msd5_mm10_ms20_div_nov_sur_qua_test', endpoint='https://huggingface.co', repo_type='dataset', repo_id='CNCL-Penn-State/cpo_en_multitask_text_fa_msd5_mm10_ms20_div_nov_sur_qua_test'), pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "input_dataset.push_to_hub(\"CNCL-Penn-State/cpo_en_multitask_text_fa_msd5_mm10_ms20_div_nov_sur_qua_test\", private=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pangea",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
